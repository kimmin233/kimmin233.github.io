---
title: "[ch01] 혼자 공부하는 머신러닝 + 딥러닝"
description: 미완성 ~.~
categories: 
 - 혼공머신
tags: [AI, Machine Learning, Deep Learning]
---

<!-- 내용 -->

# 01-1 인공지능과 머신러닝, 딥러닝

### 인공지능이란

인공지능(Artificial Intelligence) 
  : **사람처럼 학습하고 추론할 수 있는 지능**을 가진 컴퓨터 시스템을 만드는 기술.

+ 인공일반지능(Artificial General Intelligence) / 강인공지능(Strong AI)
  : 사람과 구분하기 어려운 지능을 가진 컴퓨터 시스템. 영화, 드라마 속에 등장하는 인공지능이지만 **아직 현실에서 체험하기는 어렵다.** <br>
    ex) 영화 <Her> 에 나오는 사만다, <터미네이터>에 나오는 스카이넷 등

+ 약인공지능(Week AI)
  : **현실**의 특정 분야에서 사람의 일을 도와주는 보조 역할만 가능한 인공지능.<br>
    ex) 알파고, 음성 비서, 자율 주행 자동차, 음악 추천, 기계 번역 등

아직 인공일반지능(강인공지능)에 도달하기까지 시기를 정확히 알 수 없지만 가능성은 대체로 긍정적이다.

### 머신러닝이란

머신러닝(Machine Learning)
  : 규칙을 일일이 프로그래밍하지 않아도 **자동으로 데이터에서 규칙을 학습하는 알고리즘**을 연구하는 분야.<br>
    인공지능의 하위 분야 중에서 지능을 구현하기 위한 소프트웨어를 담당하는 핵심 분야.<br>
    대표적으로 오픈소스 통계 소프트웨어인 R에 다양한 머신러닝 알고리즘이 구현되어 있음.<br><br>


사이킷런(Scikit-learn)
  : 컴퓨터 과학 분야의 대표적인 오픈소스 머신 러닝 라이브러리.<br>
    파이썬 API를 사용.<br><br>

### 딥러닝이란

딥러닝(Deep Learning)
  : 머신러닝 알고리즘 중 **인공 신경망(Artificial Neural Network)을 기반**으로 한 방법들.<br>
    인공 신경망과 딥러닝을 크게 구분하지 않고 사용하기도 한다.<br>
    복잡한 알고리즘을 훈련할 수 있는 풍부한 데이터와 컴퓨터 성능의 향상, 그리고 혁신적인 알고리즘 개발이다.<br>
    대표적으로 알파고가 있다.<br><br>


텐서플로(TensorFlow)
  : 구글의 오픈소스 딥러닝 라이브러리.<br><br>


파이토치(PyTorch)
  : 페이스북의 오픈소스 딥러닝 라이브러리.<br>


두 라이브러리들은 인공 신경망 알고리즘을 전문으로 다루고 있기 때문에 사용하기 쉬운 파이썬 API 제공.

---------------

# 01-2 코랩과 주피터 노트북

### 구글 코랩

구글 코랩(Colab)
  : 웹 브라우저에서 무료로 파이썬 프로그램을 테스트하고 저장할 수 있는 서비스.<br>
    머신 러닝 프로그램도 만들 수 있다 👉 클라우드 기반의 주피터 노트북 개발 환경 (노트북 성능과 상관 없음)<br><br>
    
  [구글 코랩](https://colab.research.google.com)  (https://colab.research.google.com)

  ![colab1](/assets/images/colab1.jpg "코랩 홈페이지 - 연결 전") <br>

  ![colab2](/assets/images/colab2.jpg "코랩 홈페이지 - 연결 후") <br>

  이러한 코랩 파일을 **노트북** 혹은 **코랩 노트북**이라고 부른다. <br>

  사진 속 코랩 로고 옆에 'Colaboratory에 오신 것을 환영합니다' 라고 적힌 것이 **노트북의 제목**. <br><br>

### 텍스트 셀

셀(cell)
 : 코랩에서 실행할 수 있는 최소 단위. <br>
   셀 안에 있는 내용을 한 번에 실행하고 그 결과를 노트북에 나타내, 자유롭게 사용할 수 있는 것이 장점. <br><br>

  ![colab7](/assets/images/colab7.jpg "텍스트 셀에서 사용하는 언어") <br>
  위와 같이 텍스트 셀에서는 HTML과 마크다운을 혼용해서 사용. <br>
  왼쪽에서 작성하면 오른쪽에서 바로 결과를 확인할 수 있다.<br><br>

### 새 노트북 만들기

1. [파일] - [새 노트] 클릭해 새 노트북 생성. <br>
 ![colab3](/assets/images/colab3.jpg "[파일] - [새 노트]") <br>

2. 생성된 노트북은 **Untitled[숫자].ipynb** 라는 이름으로 만들어지고 빈 코드의 셀 하나가 들어있다. <br>
 ![colab4](/assets/images/colab4.jpg "새 노트북 생성 ") <br>

3. `print('Hello World')` 코드 작성 후 왼쪽의 플레이 아이콘 클릭해 코드 실행. <br>
![colab5](/assets/images/colab5.jpg "Hello World 출력") <br>

4. 제목을 클릭해 수정. <br>
![colab6](/assets/images/colab6.jpg "Hello World로 제목 수정") <br>

---------------

# 01-3 마켓과 머신러닝

### 생선 분류 문제 - 첫 번째 머신러닝 프로그램

### - 크기와 무게에 따라 생선을 분류하는 프로그램을 만들어보자.

일반 프로그래밍 언어로 코딩할 경우 크기와 무게를 **미리 설정하고,** 정해진 범위에 해당하는 값을 출력한다. <br>
예를 들면 '30cm 이상 40cm 이하인 생선은 도미다' 처럼. <br>
하지만 현실에서는 25cm 도미도, 50cm 도미도 존재할 수 있는데 미리 설정된 범위에 포함되지 않는다고 도미가 다른 생선이 될 순 없는 것이다. <br>
그러므로 머신러닝으로 **데이터 셋을 미리 주어 학습시킨 후, 값을 입력하면 알아서 무엇인지 찾아주는 기능**을 구현해 볼 것이다. <br><br>
생선은 도미와 빙어 두 종류만 있다고 가정하자. <br>
먼저 도미와 빙어 데이터 셋을 준비한다. <br>
(다행히 한빛에서 데이터가 있는 링크를 준비해주셨네요 한..빛) <br>
👉 [도미](https://gist.github.com/rickiepark/b37d04a95a42ef6757e4a99214d61697), [빙어](https://gist.github.com/rickiepark/1e89fe2a9d4ad92bc9f073163c9a37a7) 

도미 데이터 셋으로 예를 들면
```python

bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]
bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0]

``` 

bream_length는 도미의 길이, bream_weight는 도미의 무게인데 이런 특징을 데이터의 **특성**이라고 한다. <br>

이 특성을 가지고 길이를 x축, 무게를 y축으로 설정해 데이터를 점으로 표시하는 그래프로 나타내보자. <br>
각 데이터를 점으로 표시하는 그래프를 **산점도**라고 한다. <br>
파이썬에서는 과학계산용 그래프를 그리는 대표적인 패키지를 **맷플롯립(matplotlib)**이라고 하는데 이 패키지의 **scatter()**함수를 사용해 그래프를 그릴 것이다. <br>
*파이썬에서는 패키지를 사용하기 위해 **import**라는 명령어를 사용한다. <br><br>

```python
import matplotlib.pyplot as plt # pyplot 함수를 plt로 줄여서 사용 

plt.scatter(bream_length, bream_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```
<br>

![fish1](/assets/images/fish1.jpg "도미 데이터 셋으로 만든 그래프") <br>

빙어 데이터 셋과 함께 산점도를 만든다.<br>
![fish2](/assets/images/fish2.jpg "도미와 빙어 데이터 셋으로 만든 그래프") <br>
도미는 파란색 점으로, 빙어는 주황색 점으로 나타내진다.<br>
이제 두 데이터를 스스로 구분하기 위한 머신러닝 프로그램을 만들자.<br>

두 데이터를 하나의 데이터로 만들어서 사용한다. <br>
```python
length = bream_length + smelt_length
weight = bream_weight + smelt_weight
```
<br>
여기서 사용하는 머신러닝 패키지는 **사이킷런(scikit-learn)**이기 때문에 합친 1차원 리스트 데이터를 2차원 리스트로 만든다.<br>
파이썬의 **zip()**함수와 리스트 내포 구문을 사용해 리스트 각각에서 하나씩 원소를 꺼내 반환해 2차원 리스트로 만든다.<br>
`fish_data = [[l,w] for l, w in zip(length, weight)]` <br>
  length와 weight 리스트에서 원소를 하나씩 꺼내어 l과 w에 할당하면 [l,w]가 하나의 원소로 구성된 리스트가 만들어진다.<br>
`print(fish_data)`로 예상대로 만들어졌는지 확인해보자. <br>

![fish3](/assets/images/fish3.jpg "데이터가 너무 많아서 짤렸지만 아래에") <br>
```python
[[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0], [29.7, 450.0], [29.7, 500.0], [30.0, 390.0], [30.0, 450.0], [30.7, 500.0], [31.0, 475.0], [31.0, 500.0], [31.5, 500.0], [32.0, 340.0], [32.0, 600.0], [32.0, 600.0], [33.0, 700.0], [33.0, 700.0], [33.5, 610.0], [33.5, 650.0], [34.0, 575.0], [34.0, 685.0], [34.5, 620.0], [35.0, 680.0], [35.0, 700.0], [35.0, 725.0], [35.0, 720.0], [36.0, 714.0], [36.0, 850.0], [37.0, 1000.0], [38.5, 920.0], [38.5, 955.0], [39.5, 925.0], [41.0, 975.0], [41.0, 950.0], [9.8, 6.7], [10.5, 7.5], [10.6, 7.0], [11.0, 9.7], [11.2, 9.8], [11.3, 8.7], [11.8, 10.0], [11.8, 9.9], [12.0, 9.8], [12.2, 12.2], [12.4, 13.4], [13.0, 12.2], [14.3, 19.7], [15.0, 19.9]]
```
<br>
이차원 리스트 완성 ! <br><br>

이제 마지막으로 필요한 데이터는 **정답 데이터**이다. <br>
도미 데이터가 35개, 빙어 데이터가 14개 있는데 앞 35개 데이터가 도미이고, 뒤의 14개 데이터가 빙어라는 것을 알려줘야 둘을 구분하는 규칙을 찾을 수 있다. <br>
1과 0을 이용해 1은 도미, 0은 빙어로 놓는다.<br>
```python
fish_target = [1] * 35 + [0] * 14
print(fish_target)
```
<br>
사이킷런 패키지의 **k-최근접 이웃** 알고리즘을 사용할 건데 이 알고리즘을 구현한 클래스인 KNeighborsClassifier를 import한다.<br>

```python
from sklearn.neighbors import KNeighborsClassifier
```
<br>
KNeighborsClassifier 클래스 객체를 만든다. <br>

```python
kn = KNeighborsClassifier() #객체명 kn
```
<br>
이 객체에 fish_data와 fish_target을 전달해 도미를 찾기 위한 기준을 학습시킨다. <br>
이런 걸 머신러닝에서 **훈련**이라고 하고 **fit()**메서드를 이용한다. <br>

```python
kn.fit(fish_data, fish_target)
```
<br>
객체 kn이 잘 훈련되었는지 평가해보자. <br>
모델을 평가하는 메서드는 **score()**메서드이고, **0에서 1 사이의 값을 반환**하는데 이 값을 **정확도**라고 한다. <br>
즉, **1은 모든 데이터를 정확히 맞췄다**는 것을 의미한다. <br>

```python
kn.score(fish_data, fish_target)
```
![fish4](/assets/images/fish4.jpg "score() 메서드 실행결과") <br>
1.0이 나온 것으로 보아 정확히 분류했다는 것을 알 수 있다. <br><br>

### - 프로그램 사용해보기

길이가 30, 무게가 600인 생선이 새로 들어왔을 경우 이 생선은 도미와 빙어중 어디에 속할까? <br>
![fish_marker](/assets/images/fish_marker.jpg "초록 세모 - 새로 들어온 생선") <br>

일단 그래프로 봤을 때 직관적으로 도미라고 판단이 되지만 실제로도 그런지 k-최근접 이웃 알고리즘을 통해 확인해보자. <br>

```python
kn.predict([[30,600]])
```
![fish5](/assets/images/fish5.jpg "predict() 메서드 실행결과") <br>
**predict()** 메서드는 입력한 데이터의 정답을 예측하는 메서드이다. <br>
fish_data가 2차원 배열이기 때문에 전달하는 값도 2차원 배열 형태로 전달해준다.<br>
앞에서 도미는 1, 방어는 0으로 학습시켰기 때문에 30, 600은 도미인 1이 나온 것을 확인할 수 있다.<br>
k-최근접 알고리즘은 데이터와 **가장 가까운 직선거리**에 어떤 데이터가 있는지 살피기만 하면 되는 장점이 있지만 데이터가 아주 많을 경우 사용하기 어렵다는 단점이 있다.
